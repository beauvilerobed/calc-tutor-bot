{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chatbot Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope of this chatbot\n",
    "We are going to build a chatbot using deep learning techniques using a **retrieval-based** approach. The chatbot will be trained on the dataset \n",
    "which contains conversation categories (intents), patterns, and responses. The model uses a Deep Neural Network with a single hidden layer to \n",
    "classify which category the input message belongs to and then the chatbot will select a random response from the list of responses, which have \n",
    "similar meaning.\n",
    "\n",
    "Topics the chatbot will be helpful with helping students finding answers to questions in the following topics:\n",
    "- Before calculus\n",
    "- Limits and continuity\n",
    "- Derivatives\n",
    "- Integrals\n",
    "\n",
    "Furthermore, this is just a prototype whose functionality can be greatly expanded in topics (other than math) it can reply to, depth of conversation, answer a\n",
    "plethra of questions and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('intents.json')\n",
    "train.head(3)\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each intent there is information on:\n",
    "- tag: Topic of conversation\n",
    "- patterns: The user input\n",
    "- responses: The chatbot's reply\n",
    "- context: A field that correlates to the tag field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('./chatbot/data/intents.json').read()\n",
    "intents = json.loads(data_file)\n",
    "\n",
    " \n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "\n",
    "        tockenized_word_patterns = nltk.word_tokenize(pattern)\n",
    "        words.extend(tockenized_word_patterns)\n",
    "        documents.append((tockenized_word_patterns, intent['tag']))\n",
    "\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process words and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words, open('./chatbot/words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('./chatbot/classes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "for document in documents:\n",
    "    bag = []\n",
    "\n",
    "    tokenized_words = document[0]\n",
    "    tokenized_words = [lemmatizer.lemmatize(word.lower()) for word in tokenized_words]\n",
    "\n",
    "    for word in words:\n",
    "        bag.append(1) if word in tokenized_words else bag.append(0)\n",
    "\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(document[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "train_x_bags = list(training[:, 0])\n",
    "train_y_output_rows = list(training[:, 1])\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x_bags[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y_output_rows[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(np.array(train_x_bags), np.array(train_y_output_rows), epochs=300, batch_size=10, verbose=1)\n",
    "model.save('./chatbot/chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
